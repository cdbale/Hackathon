---
title: "Untitled"
author: "Cameron Bale"
date: "8/29/2020"
output: html_document
---

Install and load packages.
```{r}
#install.packages(c('plyr', 'tidyverse', 'sp', 'patchwork', 'ggridges', 'spatstat', 'ggmap', 'geosphere', 'data.table'))
library(plyr)
library(tidyverse)
library(sp)
library(patchwork)
library(ggridges)
library(spatstat)
library(ggmap)
library(geosphere)
library(data.table)
```

Load cleaned data.
```{r}
load(file = "../Data/korea_data_clean.RData")
```

How many individuals in the data?
```{r}
full %>%
  distinct(patient_id) %>%
  summarize(n = n())
```

What time frame does the data cover?
```{r}
full %>%
  summarize(min_date = min(date),
            max_date = max(date))
```

What are the minimum and maximum trajectory lengths?
```{r}
full %>%
  group_by(patient_id) %>%
  summarize(n = n(), .groups = 'drop') %>%
  summarize(min_length = min(n),
            max_length = max(n))
```

Distribution of trajectory lengths.
```{r}
full %>%
  group_by(patient_id) %>%
  summarize(n = n(), .groups = 'keep') %>%
  ggplot(aes(x = n)) +
  geom_histogram(binwidth = 1) +
  labs(title = 'Trajectory Length Distribution',
       y = 'Number of Individuals',
       x = "Number of Location Tuples in Trajectories") +
  theme(text = element_text(size = 12.5))
```

Create data objects for full korea and seoul for individuals with at least five observed location points.
```{r}
full <- full %>%
  select(patient_id, latitude, longitude) %>%
  group_by(patient_id) %>%
  filter(n() > 4) %>%
  ungroup()
  
s_full <- full %>%
  filter((longitude > 126.85 & longitude < 127.15) & (latitude > 37.45 & latitude < 37.65)) %>%
  group_by(patient_id) %>%
  filter(n() > 4) %>%
  ungroup()
```

How many individuals after restriction.
```{r}
full %>%
  distinct(patient_id) %>%
  summarize(n = n())

s_full %>%
  distinct(patient_id) %>%
  summarize(n = n())
```

How many unique location tuples, and what is the percentage of unique location points?
```{r}
(np <- full %>%
  distinct(latitude, longitude) %>%
  summarize(n = n()) %>%
  pull())

nup <- full %>%
  group_by(latitude, longitude) %>%
  summarize(n = n(), .groups = 'drop') %>%
  filter(n == 1) %>%
  summarize(n = n()) %>%
  pull()

nup/np * 100
```

What percentage of individuals have a unique location trajectory?
```{r}
split_trajs <- full %>%
  select(patient_id, latitude, longitude) %>%
  group_by(patient_id) %>%
  arrange(latitude) %>%
  group_split(.keep = FALSE)

length(unique(split_trajs))/length(split_trajs) * 100
```

Calculate the density of points per square kilometer in the full dataset, excluding 16 points on an island South of the mainland (below 34 degrees latitude).
```{r}
# original data is in latitude and longitude
# have to project it onto a 2D space in terms of meters and divide by 1000 to get it in kilometers
# https://proj.org/operations/projections/utm.html
# it is a universal transverse mercator projection using the sp package
f <- full %>%
  select(longitude, latitude) %>%
  filter(latitude > 34)

coordinates(f) <- c("longitude", "latitude")
proj4string(f) <- CRS("+proj=longlat +datum=WGS84")
fm <- spTransform(f, CRS("+proj=utm +zone=52"))
fm <- as.data.frame(fm)/1000

# define window to calculate intensity in by the bounds created by the minimum and maximum observed latitude and longitude values
window <- data.frame(
  min_long = min(fm$longitude),
  min_lat = min(fm$latitude),
  max_long = max(fm$longitude),
  max_lat = max(fm$latitude)
)

# create ppp object to pass to intensity function
f_ppp <- ppp(fm$longitude, fm$latitude, c(window$min_long, window$max_long), c(window$min_lat, window$max_lat))

intensity(f_ppp)
```

Calculate the density of points per square kilometer in Seoul.
```{r}
s <- s_full %>%
  select(longitude, latitude)

coordinates(s) <- c("longitude", "latitude")
proj4string(s) <- CRS("+proj=longlat +datum=WGS84")
sm <- spTransform(s, CRS("+proj=utm +zone=52"))
sm <- as.data.frame(sm)/1000

s_window <- data.frame(
  min_long = min(sm$longitude),
  min_lat = min(sm$latitude),
  max_long = max(sm$longitude),
  max_lat = max(sm$latitude)
)

s_ppp <- ppp(sm$longitude, sm$latitude, c(s_window$min_long, s_window$max_long), c(s_window$min_lat, s_window$max_lat))

intensity(s_ppp)
```

Output maps of the full dataset and Seoul.
```{r fig.width = 10, fig.height = 8}
k_map <- ggmap(get_map(location = c(126, 33, 130, 38.5)), 
               extent = 'panel', 
               base_layer = ggplot(full, aes(x = longitude, y = latitude))) +
  geom_point(alpha = 0.4, color = 'blue') +
  labs(x = 'Longitude',
       y = 'Latitude')

print(k_map)
```

```{r}
s_map <- ggmap(get_map(location = c(126.85, 37.45, 127.15, 37.65)), 
               extent = 'panel', 
               base_layer = ggplot(s_full, aes(x = longitude, y = latitude))) +
  geom_point(alpha = 0.4, color = 'blue') +
  labs(x = '',
       y = '')

print(s_map)
```

Create maps showing coarsened trajectories.
```{r fig.width = 10, fig.height = 8}
traj_1d <- full %>%
  mutate(latitude = round(latitude, digits = 1),
         longitude = round(longitude, digits = 1))

coarse_k_map <- ggmap(get_map(location = c(126, 33, 130, 38.5)), 
               extent = 'panel', 
               base_layer = ggplot(traj_1d, aes(x = longitude, y = latitude))) +
  geom_point(alpha = 0.4, color = 'blue') +
  labs(x = 'Longitude',
       y = 'Latitude')

print(coarse_k_map)
```

```{r}
traj_1ds <- s_full %>%
  mutate(latitude = round(latitude, digits = 1),
         longitude = round(longitude, digits = 1))

coarse_s_map <- ggmap(get_map(location = c(126.85, 37.45, 127.15, 37.65)), 
               extent = 'panel', 
               base_layer = ggplot(traj_1ds, aes(x = longitude, y = latitude))) +
  geom_point(color = 'blue') +
  labs(x = '',
       y = '')

print(coarse_s_map)
```

Calculating distance between points for individual i (From paper).
```{r}
distGeo(c(127.0170, 37.59256), c(127.017, 37.593))
```

Define trajectory uniqueness function.
```{r}
trajectory_uniqueness <- function(trajectory_data, num_points, nits = 1)
{
  ntrajectories <- length(unique(trajectory_data$patient_id))
    
  p_unique <- replicate(n=nits,length(unique(lapply(split(trajectory_data[,.SD[sample(.N,num_points)],by=patient_id],by='patient_id',keep.by=FALSE),setkey,'latitude')))/ntrajectories)
  
  return(100 * p_unique)
}
```

Calculate trajectory uniqueness for original data (takes several minutes).
```{r}
up_5d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(full), num_points = x, nits = 100))
```

Rename variables and shape into long-format.
```{r}
pvar_names <- c('one', 'two', 'three', 'four', 'five')

colnames(up_5d) <- pvar_names

up_5d <- up_5d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 5)

save(up_5d, file = '../Data/pct_unique_5d.RData')
```

Repeat for d = 4.
```{r message = FALSE}
full_4d <- full %>%
  mutate(latitude2 = round(latitude, digits = 4),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude, latitude2)),
         latitude = latitude2) %>%
  select(-latitude2)

up_4d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(full[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(up_4d) <- pvar_names

up_4d <- up_4d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 4)

save(up_4d, file = '../Data/pct_unique_4d.RData')
```

We also make a function to display the quantiles of the distances that observed location points were shifted when we round `latitude` and `longitude`.
```{r}
dist_quants <- function(percentage_data){
  qs <- percentage_data %>%
    ungroup() %>%
    summarize(Min = min(distances),
            `2.5%` = quantile(distances, probs = .025),
            `50%` = median(distances),
            `97.5%` = quantile(distances, probs = 0.975),
            Max = max(distances))
  return(qs)
}
```

Repeat for d = 3.
```{r message = FALSE}
full_3d <- full %>%
  mutate(latitude2 = round(latitude, digits = 3),
         longitude2 = round(longitude, digits = 3),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

up_3d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(full_3d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(up_3d) <- pvar_names

up_3d <- up_3d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 3)

save(up_3d, file = '../Data/pct_unique_3d.RData')
```

Repeat for d = 2.
```{r message = FALSE}
full_2d <- full %>%
  mutate(latitude2 = round(latitude, digits = 2),
         longitude2 = round(longitude, digits = 2),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

up_2d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(full_2d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(up_2d) <- pvar_names

up_2d <- up_2d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 2)

save(up_2d, file = '../Data/pct_unique_2d.RData')
```

Repeat for d = 1.
```{r message = FALSE}
full_1d <- full %>%
  mutate(latitude2 = round(latitude, digits = 1),
         longitude2 = round(longitude, digits = 1),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

up_1d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(full_1d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(up_1d) <- pvar_names

up_1d <- up_1d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 1)

save(up_1d, file = '../Data/pct_unique_1d.RData')
```

Repeat for d = 0.
```{r message = FALSE}
full_0d <- full %>%
  mutate(latitude2 = round(latitude, digits = 0),
         longitude2 = round(longitude, digits = 0),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

up_0d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(full_0d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(up_0d) <- pvar_names

up_0d <- up_0d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 0)

save(up_0d, file = '../Data/pct_unique_0d.RData')
```

Load uniqueness calculations (can do this after running the above chunks once).
```{r}
# load('../Data/pct_unique_5d.RData')
# load('../Data/pct_unique_4d.RData')
# load('../Data/pct_unique_3d.RData')
# load('../Data/pct_unique_2d.RData')
# load('../Data/pct_unique_1d.RData')
# load('../Data/pct_unique_0d.RData')
```

Repeat for Seoul.
```{r}
sup_5d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(s_full), num_points = x, nits = 100))

colnames(sup_5d) <- pvar_names

sup_5d <- sup_5d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 5)

save(sup_5d, file = '../Data/s_pu_5d.Rdata')

s_full_4d <- s_full %>%
  mutate(latitude2 = round(latitude, digits = 4),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude, latitude2)),
         latitude = latitude2) %>%
  select(-latitude2)

sup_4d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(s_full_4d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(sup_4d) <- pvar_names

sup_4d <- sup_4d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 4)

save(sup_4d, file = '../Data/s_pu_4d.Rdata')

sq4d <- dist_quants(s_full_4d) %>% mutate(specificity = 4)

s_full_3d <- s_full %>%
  mutate(latitude2 = round(latitude, digits = 3),
         longitude2 = round(longitude, digits = 3),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

sup_3d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(s_full_3d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(sup_3d) <- pvar_names

sup_3d <- sup_3d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 3)

save(sup_3d, file = '../Data/s_pu_3d.Rdata')

sq3d <- dist_quants(s_full_3d) %>% mutate(specificity = 3)

s_full_2d <- s_full %>%
  mutate(latitude2 = round(latitude, digits = 2),
         longitude2 = round(longitude, digits = 2),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

sup_2d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(s_full_2d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(sup_2d) <- pvar_names

sup_2d <- sup_2d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 2)

save(sup_2d, file = '../Data/s_pu_2d.Rdata')

sq2d <- dist_quants(s_full_2d) %>% mutate(specificity = 2)

s_full_1d <- s_full %>%
  mutate(latitude2 = round(latitude, digits = 1),
         longitude2 = round(longitude, digits = 1),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

sup_1d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(s_full_1d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(sup_1d) <- pvar_names

sup_1d <- sup_1d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 1)

save(sup_1d, file = '../Data/s_pu_1d.Rdata')

sq1d <- dist_quants(s_full_1d) %>% mutate(specificity = 1)

s_full_0d <- s_full %>%
  mutate(latitude2 = round(latitude, digits = 0),
         longitude2 = round(longitude, digits = 0),
         distances = distGeo(tibble(longitude, latitude), tibble(longitude2, latitude2)),
         latitude = latitude2,
         longitude = longitude2) %>%
  select(-latitude2, -longitude2)

sup_0d <- map_dfc(1:5, function(x) trajectory_uniqueness(data.table(s_full_0d[,c(1, 2, 3)]), num_points = x, nits = 100))

colnames(sup_0d) <- pvar_names

sup_0d <- sup_0d %>%
  gather(key = 'num_points', value = 'percent_unique') %>%
  mutate(specificity = 0)

save(sup_0d, file = '../Data/s_pu_0d.Rdata')

sq0d <- dist_quants(s_full_0d) %>% mutate(specificity = 0)
```

Load uniqueness calculations (can do this after running the above chunk once).
```{r}
#load('../Data/s_pu_5d.Rdata')
#load('../Data/s_pu_4d.Rdata')
#load('../Data/s_pu_3d.Rdata')
#load('../Data/s_pu_2d.Rdata')
#load('../Data/s_pu_1d.Rdata')
#load('../Data/s_pu_0d.Rdata')
```

Plot uniqueness results for South Korea and Seoul side by side.
```{r fig.width = 10, fig.height = 8}
full_pd <- up_5d %>%
  bind_rows(up_4d, up_3d, up_2d, up_1d, up_0d)

full_s <- sup_5d %>%
  bind_rows(sup_4d, sup_3d, sup_2d, sup_1d, sup_0d)

boxes_full <- full_pd %>%
  mutate(specificity = factor(specificity, levels = c('0', '1', '2', '3', '4', '5')),
         num_points = factor(num_points, levels = c('one', 'two', 'three', 'four', 'five'))) %>%
  ggplot(aes(x = specificity, y = percent_unique, fill = factor(num_points))) +
  geom_boxplot(position = position_dodge(width = 0)) +
  labs(x = 'Number of Decimals',
       y = '% Unique Trajectories',
       fill = '# Tuples\n',
       title = 'Full Data') +
  scale_fill_discrete(labels = c('One', 'Two', 'Three', 'Four', 'Five'),
                      guide = guide_legend(reverse = TRUE)) +
  theme(legend.position = c(.9, .1),
        legend.justification = c('right', 'bottom'),
        legend.box.just = 'right',
        text = element_text(size = 12.5)) +
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 25))

boxes_s <- full_s %>%
  mutate(specificity = factor(specificity, levels = c('0', '1', '2', '3', '4', '5')),
         num_points = factor(num_points, levels = c('one', 'two', 'three', 'four', 'five'))) %>%
  ggplot(aes(x = specificity, y = percent_unique, fill = factor(num_points))) +
  geom_boxplot(position = position_dodge(width = 0)) +
  labs(x = 'Number of Decimals',
       y = '',
       fill = '# Tuples\n',
       title = 'Seoul Only') +
  scale_fill_discrete(labels = c('One', 'Two', 'Three', 'Four', 'Five'),
                      guide = guide_legend(reverse = TRUE)) +
  theme(legend.position = c(.9, .1),
        legend.justification = c('right', 'bottom'),
        legend.box.just = 'right',
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        text = element_text(size = 12.5)) +
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 25))

addSmallLegend <- function(myPlot, pointSize = 2, textSize = 10, spaceLegend = 1) {
    myPlot +
        guides(shape = guide_legend(override.aes = list(size = pointSize)),
               color = guide_legend(override.aes = list(size = pointSize))) +
        theme(legend.title = element_text(size = textSize), 
              legend.text  = element_text(size = textSize),
              legend.key.size = unit(spaceLegend, "lines"))
}

addSmallLegend(boxes_full) | addSmallLegend(boxes_s)
```

Calculate the average percentage of unique trajectories across all simulations at each value of d.
```{r}
full_pd %>% group_by(specificity) %>% summarize(avg_pct_unique = mean(percent_unique), .groups = 'drop')
```

```{r}
full_s %>% group_by(specificity) %>% summarize(avg_pct_unique = mean(percent_unique), .groups = 'drop')
```

Distances shifted for full data.
```{r}
q4d <- dist_quants(full_4d) %>% mutate(specificity = 4)

q3d <- dist_quants(full_3d) %>% mutate(specificity = 3)

q2d <- dist_quants(full_2d) %>% mutate(specificity = 2)

q1d <- dist_quants(full_1d) %>% mutate(specificity = 1)

q0d <- dist_quants(full_0d) %>% mutate(specificity = 0)

q4d %>% bind_rows(q3d, q2d, q1d, q0d) %>% round(digits = 2)
```

Percent and number of coarsened locations meeting the Singling-out requirement when releasing aggregate counts.
```{r}
bin_dist <- function(loc_data, num_dec) {
  
  loc_data %>%
    transmute(latitude = round(latitude, num_dec),
              longitude = round(longitude, num_dec)) %>%
    group_by(latitude, longitude) %>%
    summarize(n = n(), .groups = 'drop') %>%
    select(n) %>%
    mutate(d = factor(num_dec))
  
}

bin_dists <- bin_dist(full, num_dec = 5) %>%
  bind_rows(bin_dist(full, num_dec = 4),
            bin_dist(full, num_dec = 3),
            bin_dist(full, num_dec = 2),
            bin_dist(full, num_dec = 1),
            bin_dist(full, num_dec = 0))

bin_dists %>%
  mutate(not_singled_out = if_else(n > 1, 1, 0)) %>%
  group_by(d) %>%
  summarize(pct_nso = mean(not_singled_out) * 100,
            num_nso = sum(not_singled_out), .groups = 'drop')
```

Repeat for Seoul.
```{r}
bin_dists_s <- bin_dist(s_full, num_dec = 5) %>%
  bind_rows(bin_dist(s_full, num_dec = 4),
            bin_dist(s_full, num_dec = 3),
            bin_dist(s_full, num_dec = 2),
            bin_dist(s_full, num_dec = 1),
            bin_dist(s_full, num_dec = 0))

bin_dists_s %>%
  mutate(not_singled_out = if_else(n > 1, 1, 0)) %>%
  group_by(d) %>%
  summarize(pct_nso = mean(not_singled_out) * 100,
            num_nso = sum(not_singled_out), .groups = 'drop')
```

Calculate the areas and side lengths of all regions in the data.
```{r}
# make a function for calculating polygon boundaries and area
# designed to take vectors or dataframe columns of latitude and longitude values. Reports the area over which points would
# have been coarsened to the corresponding lat/long point
# this function is specific to this data i.e. it is assumed that latitude originally had 5 decimals, and longitude had 4
poly_area <- function(lat, long) {
  
  # create point data
  pt <- data.frame(lat, long)
  
  # calculate the number of decimal places of the points
  # the only time the number of decimals isn't equal between lat/long is when no rounding is performed
  num_dec <- nchar(str_split(as.character(pt[1,1]), pattern = "\\.")[[1]][2])
  
  num_dec <- ifelse(is.na(num_dec), 0, num_dec)
  
  # get the minimum latitude/longitude values that correspond to the edges of the polygon
  pt$min_lat <- pt$lat - as.numeric(paste0(".", str_pad("5", num_dec + 1, pad = "0")))
  pt$min_long <- pt$long - as.numeric(paste0(".", str_pad("5", num_dec + 1, pad = "0")))
  
  # get the maximum latitude/longitude values that correspond to the edges of the polygon
  pt$max_lat <- pt$lat + as.numeric(paste0(".", str_pad(str_pad("4", num_dec + 1, pad = "0"), 5, pad = "9", side = "right")))
  pt$max_long <- pt$long + as.numeric(paste0(".", str_pad(str_pad("4", num_dec + 1, pad = "0"), 4, pad = "9", side = "right")))
  
  A <- data.frame(apply(pt[,3:6], 1, function(x) 
  {pol <- rbind(c(x[2], x[1]),
                c(x[2], x[3]),
                c(x[4], x[3]),
                c(x[4], x[1]),
                c(x[2], x[1]))
  areaPolygon(pol)}))
  
  names(A) <- "area"
  
  # vertical (or latitudinal) lengths are equal, only need to take one
  A$vert_length <- distGeo(data.frame(pt$max_long, pt$max_lat), data.frame(pt$max_long, pt$min_lat))
  
  # horizontal (or longitudinal) lengths are slightly different, the northern side will be slightly shorter
  # we take the average of the two
  A$hor_length <- apply(data.frame(distGeo(data.frame(pt$max_long, pt$max_lat), data.frame(pt$min_long, pt$max_lat)),
                                   distGeo(data.frame(pt$max_long, pt$min_lat), data.frame(pt$min_long, pt$min_lat))),
                        1, mean)
  
  return(A)
  
}
```

Function to calculate average side lengths and area for regions.
```{r}
poly_stats <- function(trajectory_data) {
  trajectory_data %>%
  summarize(hor_length = mean(hor_length),
            vert_length = mean(vert_length),
            p_area_m = mean(area),
            p_area_km = mean(area)/1000000)
}
```

Calculate areas and side lengths for all regions.
```{r}
full_4d <- bind_cols(full_4d, poly_area(full_4d$latitude, full_4d$longitude)) %>%
  ungroup()

full_3d <- bind_cols(full_3d, poly_area(full_3d$latitude, full_3d$longitude)) %>%
  ungroup()

full_2d <- bind_cols(full_2d, poly_area(full_2d$latitude, full_2d$longitude)) %>%
  ungroup()

full_1d <- bind_cols(full_1d, poly_area(full_1d$latitude, full_1d$longitude)) %>%
  ungroup()

full_0d <- bind_cols(full_0d, poly_area(full_0d$latitude, full_0d$longitude)) %>%
  ungroup()
```

Calculate average dimensions across regions.
```{r}
poly_stats(full_4d) %>%
  mutate(hor_length = 0, p_area_m = 0, p_area_km = 0) %>%
  bind_rows(poly_stats(full_3d), 
            poly_stats(full_2d), 
            poly_stats(full_1d), 
            poly_stats(full_0d)) %>%
  mutate_at(.vars = c('hor_length', 'vert_length', 'p_area_km'), round, digits = 2) %>%
  mutate_at(.vars = 'p_area_m', round, digits = 1) %>%
  mutate(specificity = 4:0)
```

### Assessing Inference for Trajectories

Function to simulate an adversary having external information location tuples corresponding to an individual i and linking them to location trajectories in Y to determine the COVID-19 status of individual i.
```{r}
inference_simulation <- function(loc_data, ci_length, prior = 0.01) {

  pos <- 0
  
  # loop to guarantee some COVID-19 positive individuals in the data
  # simulate 1% of individuals in Y as COVID-19 positive
  
  while(pos == 0) {
    
    status_data <- loc_data %>% 
      group_by(patient_id) %>%
      mutate(status = sample(c(0, 1), size = 1, prob = c(.99, .01))) %>%
      ungroup()
    
    ptv_inds <- status_data %>%
      filter(status == 1)
    
    pos <- nrow(ptv_inds)
    
  }
  
  # sample external information tuples from each COVID-19 positive individal trajectory
  ci <- ptv_inds %>%
    group_by(patient_id) %>%
    sample_n(size = ci_length) %>%
    group_split()
  
  # remove patient id and status from external information
  ci1 <- lapply(ci, function(x) x %>% select(-patient_id, -status))

  # summarize the number of times each latitude/longitude tuple occurs in each external information set
  ci2 <- lapply(ci1, function(x) x %>% group_by(latitude, longitude) %>% summarize(n = n(), .groups = 'drop'))
  
  # find the 'matches' or the individuals whose trajectories contain the external information tuples
  matches <- lapply(ci2, function(y) match_df(status_data, y, on = c('latitude', 'longitude')) %>%
                                     group_by(patient_id, latitude, longitude, status) %>%
                                     summarize(n1 = n(), .groups = 'drop'))

  # join the matches data to the external information tuples data
  links <- lapply(1:length(ci2), function(x) left_join(matches[[x]], ci2[[x]], by = c('latitude', 'longitude')))

  # filter for the individuals whose trajectories are supersets of the external information (based on the tuples occurring at least as many times as in the external information)
  links2 <- lapply(1:length(links), function(x) links[[x]] %>% group_by(patient_id) %>% filter(n1 >= n & n() >= nrow(ci2[[x]])) %>% ungroup())

  # reduce to list of patient_id and COVID-19 status
  covid_count <- lapply(links2, function(x) distinct(x, patient_id, status))

  # calculate left hand side of inference condition for each COVID-19 positive individual
  inf_props <- map_dfr(covid_count, function(x) x %>% summarize(cond = mean(status) - prior))

  # average the left hand side of the inference condition across COVID-19 positive individuals
  avg_cond <- inf_props %>% summarize(avg_cond = mean(cond))
  
  return(avg_cond)
  
}
```

Function to perform simulation one hundred times each for one to five external information tuples based on an input dataset and a specified value of d (num_dec).
```{r}
inf_calc <- function(location_data, num_dec, nits = 100, sample_sizes = 1:5, pvar_names = c('one', 'two', 'three', 'four', 'five')) {
  
  loc_data <- location_data %>%
    mutate_at(.vars = c('latitude', 'longitude'), round, digits = num_dec)
  
  props <- map_dfc(1:5, function(y) map_dfr(1:100, function(x) inference_simulation(loc_data, y)))
  
  colnames(props) <- pvar_names
  
  props_g <- props %>%
    gather(key = 'num_points', value = 'inf_prop') %>%
    mutate(specificity = num_dec)
  
  return(props_g)
  
}
```

Inference analysis for full data.
```{r fig.width=6, fig.height=6}
inf_results <- inf_calc(full, 5) %>%
  bind_rows(inf_calc(full, 4)) %>%
  bind_rows(inf_calc(full, 3)) %>%
  bind_rows(inf_calc(full, 2)) %>%
  bind_rows(inf_calc(full, 1)) %>%
  bind_rows(inf_calc(full, 0))

i_p <- inf_results %>%
  mutate(specificity = factor(specificity, levels = c('0', '1', '2', '3', '4', '5')),
         num_points = factor(num_points, levels = c('one', 'two', 'three', 'four', 'five'))) %>%
  ggplot(aes(x = specificity, y = inf_prop, fill = factor(num_points))) +
  geom_boxplot(position = position_dodge(width = 0.5)) +
  labs(x = 'Number of decimals d',
       y = 'Individual-level Average of LHS of Inference Condition',
       fill = '# EI Tuples\n',
       title = 'Full Data') +
  scale_fill_discrete(labels = c('One', 'Two', 'Three', 'Four', 'Five'),
                      guide = guide_legend(reverse = TRUE)) +
  theme(legend.position = c(0.025, 0.95),
        legend.justification = c('left', 'top'),
        legend.box.just = 'left',
        text = element_text(size = 12.5))

addSmallLegend(i_p)
```

Inference analysis for Seoul data.
```{r fig.width=6, fig.height=6}
inf_results_s <- inf_calc(s_full, 5) %>%
  bind_rows(inf_calc(s_full, 4)) %>%
  bind_rows(inf_calc(s_full, 3)) %>%
  bind_rows(inf_calc(s_full, 2)) %>%
  bind_rows(inf_calc(s_full, 1)) %>%
  bind_rows(inf_calc(s_full, 0))

i_p_s <- inf_results_s %>%
  mutate(specificity = factor(specificity, levels = c('0', '1', '2', '3', '4', '5')),
         num_points = factor(num_points, levels = c('one', 'two', 'three', 'four', 'five'))) %>%
  ggplot(aes(x = specificity, y = inf_prop, fill = factor(num_points))) +
  geom_boxplot(position = position_dodge(width = 0.5)) +
  labs(x = 'Number of decimals d',
       y = '',
       fill = '# EI Tuples\n',
       title = 'Seoul Only') +
  scale_fill_discrete(labels = c('One', 'Two', 'Three', 'Four', 'Five'),
                      guide = guide_legend(reverse = TRUE)) +
  theme(legend.position = c(0.025, 0.95),
        legend.justification = c('left', 'top'),
        legend.box.just = 'left',
        text = element_text(size = 12.5),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

addSmallLegend(i_p_s)
```

```{r fig.width=11, fig.height=7}
addSmallLegend(i_p) | addSmallLegend(i_p_s)
```

### Inference analysis for Counts.

Function to simulate an adversary having access to one location tuple corresponding to individual i and linking that tuple to the count for that tuple in an aggregated counts database to determine the COVID-19 status of that individual.
```{r}
inf_counts <- function(location_data, num_dec, prior = 0.01) {
  
  num_pos <- 0
  
  # while loop to guarantee COVID-19 positive individuals
  while(num_pos == 0) {
    
    status_data <- location_data %>% 
      group_by(patient_id) %>%
      mutate(status = sample(c(0, 1), size = 1, prob = c(.99, .01))) %>%
      ungroup()
    
    ptv_inds <- status_data %>%
      filter(status == 1)
    
    num_pos <- nrow(ptv_inds)
    
  }
  
  # round data to specified value of d
  c_status_data <- status_data %>%
    mutate_at(.vars = c('latitude', 'longitude'), round, digits = num_dec)
  
  # get all distinct location tuples for COVID-19 positive individuals
  covid_locs <- c_status_data %>%
    filter(status == 1) %>%
    distinct(latitude, longitude)
  
  # calculate the left hand side of the inference condition for each region visited by COVID-19 positive individuals
  count_props <- match_df(c_status_data, covid_locs, on = c('latitude', 'longitude')) %>%
    group_by(latitude, longitude) %>%
    summarize(inc_inf = mean(status) - prior, .groups = 'drop')

  # merge the calculations for the inference condition to the data for COVID-19 positive individuals
  # calculate the average of the inference condition across the regions visited by each individual - produces an average across   regions for each individual
  ind_avg_count_props <- ptv_inds %>%
    mutate_at(.vars = c('latitude', 'longitude'), round, digits = num_dec) %>%
    distinct(patient_id, latitude, longitude) %>%
    left_join(count_props, by = c('latitude', 'longitude')) %>%
    group_by(patient_id) %>%
    summarize(avg_inc_inf = mean(inc_inf), .groups = 'drop') %>%
    select(avg_inc_inf) %>%
    mutate(specificity = num_dec)
    
  return(ind_avg_count_props)
    
}
```

Perform simulation 100 times for Full data for d = 0,1,2,3,4,5 and plot results.
```{r}
inf_count_dists <- map_dfr(0:5, function(y) map_dfr(1:100, function(x) inf_counts(full, y))) %>%
  mutate(specificity = factor(specificity, levels = c('0', '1', '2', '3', '4', '5')))

count_inf_full <- inf_count_dists %>%
  ggplot(aes(x = specificity, y = avg_inc_inf)) +
  geom_boxplot() +
  labs(x = 'Number of decimals',
       y = 'Individual Level Average of LHS of Condition (2.5)',
       title = 'Full Data') +
  scale_y_continuous(limits = c(-.05, 1), breaks = seq(0, 1, by = .25)) +
  theme(text = element_text(size = 12.5))
```

Repeat for Seoul.
```{r}
inf_count_dists_s <- map_dfr(0:5, function(y) map_dfr(1:100, function(x) inf_counts(s_full, y))) %>%
  mutate(specificity = factor(specificity, levels = c('0', '1', '2', '3', '4', '5')))

count_inf_s <- inf_count_dists_s %>%
  ggplot(aes(x = specificity, y = avg_inc_inf)) +
  geom_boxplot() +
  labs(y = '',
       x = 'Number of decimals',
       title = 'Seoul Only') +
  scale_y_continuous(limits = c(-.05, 1), breaks = seq(0, 1, by = .25)) +
  theme(text = element_text(size = 12.5),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

```{r fig.width=11, fig.height=7}
count_inf_full | count_inf_s
```

